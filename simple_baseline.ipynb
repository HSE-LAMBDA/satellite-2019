{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as LR\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVR as LSVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train simple baseline (Linear Regression models)\n",
    "\n",
    "metric: [MAPE](https://en.wikipedia.org/wiki/Mean_absolute_percentage_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('ephemerides.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train: 17520\n",
      "n_val: 4380\n",
      "n_test: 9400\n"
     ]
    }
   ],
   "source": [
    "# target variables columns \n",
    "target_cols = ['x', 'y', 'z', 'Vx', 'Vy', 'Vz']\n",
    "# features columns \n",
    "feature_cols = [c for c in df.columns if c not in target_cols and c != 'time']\n",
    "# number of rows for training, validation and prediction\n",
    "n_train = df.shape[0] - np.isnan(df[target_cols[0]]).sum()\n",
    "n_val = int(0.2 * n_train)\n",
    "n_train = n_train - n_val\n",
    "n_test = df.shape[0] - n_train - n_val\n",
    "\n",
    "print(f\"n_train: {n_train}\\nn_val: {n_val}\\nn_test: {n_test}\")\n",
    "assert n_train + n_val + n_test == df.shape[0]\n",
    "\n",
    "# train, validation, test arrays\n",
    "X_train = df[feature_cols].values[:n_train]\n",
    "y_train = dict(zip(target_cols, [df[l].values[:n_train] for l in target_cols]))\n",
    "X_val = df[feature_cols].values[n_train:n_train+n_val]\n",
    "y_val = dict(zip(target_cols, [df[l].values[n_train:n_train+n_val] for l in target_cols]))\n",
    "X_test = df[feature_cols].values[n_train+n_val:]\n",
    "\n",
    "assert X_train.shape[0] == y_train[target_cols[0]].shape[0] == n_train\n",
    "assert X_val.shape[0] == y_val[target_cols[0]].shape[0] == n_val\n",
    "assert X_test.shape[0] == n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class SplitModel(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, model, **params):\n",
    "        self._model = model\n",
    "        self._params = params\n",
    "        self._id_to_model = {}\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        ids = np.unique(X[:, 0].astype(\"int32\"))\n",
    "        \n",
    "        for sid in ids:\n",
    "            mask = X[:, 0].astype(\"int32\") == sid\n",
    "            base = self._model(**self._params)\n",
    "            self._id_to_model[sid] = base.fit(X[:, 1:][mask], y[mask])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        ids = np.unique(X[:, 0].astype(\"int32\"))\n",
    "        assert np.all([xid in self._id_to_model for xid in ids])\n",
    "        \n",
    "        \n",
    "        prediction = np.zeros(X.shape[0])\n",
    "        for sid in ids:\n",
    "            mask = X[:, 0].astype(\"int32\") == sid\n",
    "            prediction[mask] = self._id_to_model[sid].predict(X[:, 1:][mask])\n",
    "            \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "\n",
    "scaler = SS()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "MAPE train:  2.864334376253391\n",
      "MAPE val:  4.303477513120269 \n",
      "\n",
      "y\n",
      "MAPE train:  1.9390680432773817\n",
      "MAPE val:  0.9039356458500325 \n",
      "\n",
      "z\n",
      "MAPE train:  3.0091830469543233\n",
      "MAPE val:  0.9205662275528902 \n",
      "\n",
      "Vx\n",
      "MAPE train:  1.4180215037853052\n",
      "MAPE val:  2.3662806153444893 \n",
      "\n",
      "Vy\n",
      "MAPE train:  1.7871230285990598\n",
      "MAPE val:  1.6511369096539334 \n",
      "\n",
      "Vz\n",
      "MAPE train:  1.9287174769308062\n",
      "MAPE val:  1.8758708529952959 \n",
      "\n",
      "------\n",
      "mean MAPE train:  2.157741245966711\n",
      "mean MAPE val:  2.0035446274194855\n"
     ]
    }
   ],
   "source": [
    "# dictionary: {variable: LR predictions}\n",
    "y_test = {}\n",
    "\n",
    "_mape_train_list = []\n",
    "_mape_val_list = []\n",
    "\n",
    "params = {\n",
    "    \"x\": {\"C\": 50., \"random_state\": 146},\n",
    "    \"y\": {},\n",
    "    \"z\": {}, \n",
    "    \"Vx\": {}, \n",
    "    \"Vy\": {}, \n",
    "    \"Vz\": {}\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"x\": LSVR,\n",
    "    \"y\": LR,\n",
    "    \"z\": LR,\n",
    "    \"Vx\": LR,\n",
    "    \"Vy\": LR,\n",
    "    \"Vz\": LR,\n",
    "}\n",
    "\n",
    "for k, v in y_train.items():\n",
    "#for k, v in {\"Vx\": y_train[\"Vx\"]}.items():\n",
    "    model = models[k](**(params[k])).fit(X_train, v)\n",
    "    mape_train = np.mean(np.abs((model.predict(X_train) - v) / v)) * 100\n",
    "    _mape_train_list.append(mape_train)\n",
    "    mape_val = np.mean(np.abs((model.predict(X_val) - y_val[k]) / y_val[k])) * 100\n",
    "    _mape_val_list.append(mape_val)\n",
    "    model = models[k](**(params[k])).fit(\n",
    "        np.vstack([X_train, X_val]), np.hstack([v, y_val[k]]))\n",
    "    y_test[k] = model.predict(X_test)\n",
    "    print(k)\n",
    "    print(\"MAPE train: \", mape_train)\n",
    "    print(\"MAPE val: \", mape_val, \"\\n\")\n",
    "\n",
    "print(\"------\")\n",
    "print(\"mean MAPE train: \", np.mean(_mape_train_list))\n",
    "print(\"mean MAPE val: \", np.mean(_mape_val_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "predictions = pd.DataFrame(y_test, index=df.index[-n_test:])\n",
    "predictions.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
