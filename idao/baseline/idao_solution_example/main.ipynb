{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, namedtuple\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from copy import copy\n",
    "from math import sin, cos, tan, acos, atan\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = \"../data/train.csv\"\n",
    "PATH_TEST = \"../data/test.csv\"\n",
    "PATH_SAVE = \"sub_idao_example.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_features = ['x_sim', 'y_sim', 'z_sim', 'Vx_sim', 'Vy_sim', 'Vz_sim']\n",
    "features = ['x', 'y', 'z', 'Vx', 'Vy', 'Vz']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Операции со времененем\n",
    "sub_time - возвращает time1 - time2 в секундах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_int(times, start_time):\n",
    "    return np.array([sub_time(time, start_time) for time in times])\n",
    "        \n",
    "def sub_time(time1, time2):\n",
    "    time1 = datetime.strptime(time1, '%Y-%m-%dT%H:%M:%S.%f')\n",
    "    time2 = datetime.strptime(time2, '%Y-%m-%dT%H:%M:%S.%f')\n",
    "    \n",
    "    month = time1.month - time2.month\n",
    "    day = time1.day - time2.day\n",
    "    hour = time1.hour - time2.hour\n",
    "    minute = time1.minute - time2.minute\n",
    "    second = time1.second - time2.second\n",
    "    millisecond = (time1.microsecond - time2.microsecond) // 1000\n",
    "    \n",
    "    sec_mult = 1\n",
    "    min_mult = 60  * sec_mult\n",
    "    hour_mult = 60 * min_mult\n",
    "    day_mult = 24 * hour_mult\n",
    "    \n",
    "    month_len = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    month_mult = sum(month_len[time2.month:time1.month]) * day_mult\n",
    "    \n",
    "    mults = np.array([sec_mult, min_mult, hour_mult, day_mult, month_mult])\n",
    "    diffs = np.array([second, minute, hour, day, month])\n",
    "    \n",
    "    return sum(diffs * mults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скейлит данные\n",
    "Скейлит только время и реальные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_COEF = 60 * 60 * 24 * 55\n",
    "\n",
    "\n",
    "class Transformer():\n",
    "    def __init__(self):\n",
    "        self.scalers = [StandardScaler() for _ in range(6)]\n",
    "        self.time_sc = StandardScaler()\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        X = data[sim_features + ['epoch']].to_numpy()\n",
    "        y = data[features].to_numpy()\n",
    "        \n",
    "        self.start_time = X[0, 6]\n",
    "        X[:, 6] = time_to_int(X[:, 6], self.start_time) / TIME_COEF\n",
    "        \n",
    "        for i in range(6):\n",
    "            y[:, i] = self.scalers[i].fit_transform(y[:, i].reshape(-1, 1)).reshape(-1)\n",
    "        return X, y\n",
    "    \n",
    "    def fit_transform_test(self, data_train, data_test):\n",
    "        X_train = data_train[sim_features + ['epoch']].to_numpy()\n",
    "        X_test = data_test[sim_features + ['epoch']].to_numpy()\n",
    "        y = data_train[features].to_numpy()\n",
    "        \n",
    "        self.start_time = X_train[0, 6]\n",
    "        self.time_sc.fit(np.hstack([time_to_int(X_train[:, 6], self.start_time), time_to_int(X_test[:, 6], self.start_time)]).reshape(-1, 1))\n",
    "        \n",
    "        X_train = self.transform(data_train)\n",
    "        X_test  = self.transform(data_test)\n",
    "        \n",
    "        for i in range(6):\n",
    "            self.scalers[i].fit(np.hstack([y[:, i], X_train[:, i], X_test[:, i]]).reshape(-1, 1))\n",
    "            \n",
    "            y[:, i] = self.scalers[i].transform(y[:, i].reshape(-1, 1)).reshape(-1)\n",
    "        \n",
    "        return X_train, X_test, y\n",
    "        \n",
    "\n",
    "    def transform(self, data):\n",
    "        X = data[sim_features + ['epoch']].to_numpy()\n",
    "        X[:, 6] = self.time_sc.transform(time_to_int(X[:, 6], self.start_time).reshape(-1, 1)).reshape(-1)\n",
    "        return X\n",
    "            \n",
    "\n",
    "    def inverse_transform(self, y):\n",
    "        for i in range(6):\n",
    "            y[:, i] = self.scalers[i].inverse_transform(y[:, i].reshape(-1, 1)).reshape(-1)    \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делит numpy.array на две части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, train_size):\n",
    "    index = int(len(X) * train_size)\n",
    "    \n",
    "    return X[:index], X[index:], y[:index], y[index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аппроксимация периодической функцией\n",
    "Пока не используется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = np.float64(1e-6)\n",
    "\n",
    "class Xsin():\n",
    "    def __init__(self, X_train, y_train, alpha=0.01):\n",
    "        self.f = func(X_train.reshape(-1), y_train, alpha)\n",
    "        self.g = grad(self.f)\n",
    "        \n",
    "        self.w = minimize(fun=self.f, x0=np.ones((8)), method='BFGS', jac=self.g, tol=TOL).x\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        w = self.w\n",
    "        return np.array([optimizing_f(self.w, x) for x in X_test.reshape(-1)])\n",
    "       \n",
    "        \n",
    "def optimizing_f(w, x):\n",
    "    return w[0] + w[1] * x + w[2] * sin(w[3] + w[4] * x) + w[5] * cos(w[6] + w[7] * x)\n",
    "\n",
    "def func(X_train, y_train, alpha):\n",
    "    def f(w):\n",
    "        ans = []\n",
    "        for x, y in zip(X_train, y_train):\n",
    "            res = optimizing_f(w, x)\n",
    "            #ans.append(abs(res - y) / (abs(res) + abs(y)) + alpha * w[1] ** 2)\n",
    "            ans.append((res - y) ** 2 + alpha * np.linalg.norm(w) ** 2)\n",
    "            \n",
    "        return np.float64(np.mean(np.array(ans)))\n",
    "    \n",
    "    return f\n",
    "\n",
    "def grad(f):\n",
    "    def g(w):\n",
    "        ans = []\n",
    "        for i in range(8):\n",
    "            d = np.float64(np.zeros((8)))\n",
    "            d[i] = EPS\n",
    "            \n",
    "            ans.append((f(w + d) - f(w - d)) / (2 * EPS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кластеризует траекторию одного спутника"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterize(data):\n",
    "    times = list(data['epoch'])\n",
    "    prev_time = times[0]\n",
    "    cluster_index = 0\n",
    "    clusters = [[] for _ in range(24)]\n",
    "    clusters[0].append(0)\n",
    "    \n",
    "    for i in range(1, len(times)):\n",
    "        if sub_time(times[i], prev_time) > 10:\n",
    "            cluster_index = (cluster_index + 1) % 24\n",
    "        \n",
    "        clusters[cluster_index].append(i)\n",
    "        prev_time = times[i]\n",
    "            \n",
    "    return [data.iloc[cluster] for cluster in clusters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение и кластеризация трейновых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.read_csv(PATH_TRAIN, index_col=0)\n",
    "test_data_full = pd.read_csv(PATH_TEST, index_col=0)\n",
    "# total_data['id'] = total_data.index\n",
    "# test_data_full['id'] = test_data_full.index\n",
    "\n",
    "total_data['id'] = total_data.index\n",
    "test_data_full['id'] = test_data_full.index\n",
    "\n",
    "SAT_N = len(pd.unique(total_data[\"sat_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../data_KSD_RP.csv\", index_col=0)\n",
    "# df['id'] = df.index\n",
    "# # df.index.names = ['id']\n",
    "\n",
    "# test_date = \"2014-02-01T00:00:00.000\"\n",
    "# train_idxs = (df[\"epoch\"] < test_date).values\n",
    "# df_train = df[train_idxs]\n",
    "# df_test = df[np.invert(train_idxs)]\n",
    "# df_test_sgp4 = df_test[[\"id\", \"sat_id\", \"epoch\", \"x_sim\", \"y_sim\", \"z_sim\", \"Vx_sim\", \"Vy_sim\", \"Vz_sim\"]]\n",
    "# df_test_ans = df_test[[\"id\", \"sat_id\", \"x\", \"y\", \"z\", \"Vx\", \"Vy\", \"Vz\"]]\n",
    "\n",
    "# SAT_N = len(pd.unique(df_train[\"sat_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_data = df_train.drop(['RP', 'KSD'], axis=1)\n",
    "# test_data_full = df_test_sgp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = total_data\n",
    "clusters_list = []\n",
    "for sat_id in range(SAT_N):\n",
    "    clusters_list.append(clusterize(data[data['sat_id'] == sat_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение и кластеризация тестовых данных (для трека А)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sat_id</th>\n",
       "      <th>epoch</th>\n",
       "      <th>x_sim</th>\n",
       "      <th>y_sim</th>\n",
       "      <th>z_sim</th>\n",
       "      <th>Vx_sim</th>\n",
       "      <th>Vy_sim</th>\n",
       "      <th>Vz_sim</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-02-01T00:05:07.344</td>\n",
       "      <td>-28099.394464</td>\n",
       "      <td>-31393.873066</td>\n",
       "      <td>27879.580116</td>\n",
       "      <td>-2.048926</td>\n",
       "      <td>1.980606</td>\n",
       "      <td>-1.879962</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-02-01T03:32:46.448</td>\n",
       "      <td>-42644.222149</td>\n",
       "      <td>-288.393217</td>\n",
       "      <td>-1087.275407</td>\n",
       "      <td>0.015348</td>\n",
       "      <td>2.814050</td>\n",
       "      <td>-2.577676</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-02-01T07:00:25.552</td>\n",
       "      <td>-27979.382752</td>\n",
       "      <td>31096.467597</td>\n",
       "      <td>-29369.026222</td>\n",
       "      <td>2.033737</td>\n",
       "      <td>2.029262</td>\n",
       "      <td>-1.794169</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-02-01T10:28:04.656</td>\n",
       "      <td>896.126549</td>\n",
       "      <td>49712.580025</td>\n",
       "      <td>-45492.481646</td>\n",
       "      <td>2.433120</td>\n",
       "      <td>1.022877</td>\n",
       "      <td>-0.859440</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-02-01T13:55:43.760</td>\n",
       "      <td>30391.384369</td>\n",
       "      <td>58185.560870</td>\n",
       "      <td>-52301.500238</td>\n",
       "      <td>2.267209</td>\n",
       "      <td>0.390206</td>\n",
       "      <td>-0.285250</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sat_id                    epoch         x_sim         y_sim  \\\n",
       "id                                                                 \n",
       "215       0  2014-02-01T00:05:07.344 -28099.394464 -31393.873066   \n",
       "216       0  2014-02-01T03:32:46.448 -42644.222149   -288.393217   \n",
       "217       0  2014-02-01T07:00:25.552 -27979.382752  31096.467597   \n",
       "218       0  2014-02-01T10:28:04.656    896.126549  49712.580025   \n",
       "219       0  2014-02-01T13:55:43.760  30391.384369  58185.560870   \n",
       "\n",
       "            z_sim    Vx_sim    Vy_sim    Vz_sim   id  \n",
       "id                                                    \n",
       "215  27879.580116 -2.048926  1.980606 -1.879962  215  \n",
       "216  -1087.275407  0.015348  2.814050 -2.577676  216  \n",
       "217 -29369.026222  2.033737  2.029262 -1.794169  217  \n",
       "218 -45492.481646  2.433120  1.022877 -0.859440  218  \n",
       "219 -52301.500238  2.267209  0.390206 -0.285250  219  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_ids = list(set(test_data_full['sat_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clusters_list = []\n",
    "for sat_id in range(SAT_N):\n",
    "    if  sat_id not in sat_ids:\n",
    "        test_clusters_list.append([])\n",
    "    else:\n",
    "        test_clusters_list.append(clusterize(test_data_full[test_data_full['sat_id'] == sat_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перестановка тестовых кластеров в таком же порядке, как и трейновых"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_clusters():\n",
    "    for sat_id in sat_ids:\n",
    "        reorder_clusters_id(sat_id)\n",
    "        \n",
    "def reorder_clusters_id(sat_id):\n",
    "    train_clusters = clusters_list[sat_id]\n",
    "    test_clusters = test_clusters_list[sat_id]\n",
    "    test_cluster = test_clusters_list[sat_id][0]\n",
    "        \n",
    "    period = average_period(test_cluster)\n",
    "    dists = [cluster_distance(train_cluster, test_cluster, period) for train_cluster in train_clusters]\n",
    "        \n",
    "    offset, dist = min(enumerate(dists), key=lambda x: x[1])\n",
    "    \n",
    "    assert dist < 2\n",
    "        \n",
    "    ordered_clusters = [test_clusters[(24 - offset + i) % 24] for i in range(24)]\n",
    "    test_clusters_list[sat_id] = ordered_clusters\n",
    "    \n",
    "def cluster_distance(train_cluster, test_cluster, period):\n",
    "    train_time = train_cluster['epoch'].to_numpy()[-1]\n",
    "    test_time = test_cluster['epoch'].to_numpy()[0]\n",
    "    \n",
    "    return float_mod(train_time, test_time, period)\n",
    "\n",
    "def float_mod(t1, t2, period):\n",
    "    time_diff = sub_time(t2, t1)\n",
    "    mod_value = int(time_diff / period)\n",
    "    return min(time_diff - period * mod_value, period * (mod_value + 1) - time_diff)\n",
    "\n",
    "def average_period(cluster):\n",
    "    times = cluster['epoch'].to_numpy()\n",
    "    periods = []\n",
    "    for i in range(1, len(times)):\n",
    "        time_dist = sub_time(times[i], times[i - 1])\n",
    "        if time_dist > 1:\n",
    "            periods.append(time_dist)\n",
    "    \n",
    "    return np.mean(np.array(periods))\n",
    "\n",
    "\n",
    "def find_example(times):\n",
    "    time1, time2 = times\n",
    "    if sub_time(time2, time1) < 100:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "reorder_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание для пункта А"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [03:32<00:00,  2.94it/s]\n"
     ]
    }
   ],
   "source": [
    "results = [[] for _ in range(7)]\n",
    "\n",
    "def split(X, rate):\n",
    "    index = int(len(X) * rate)\n",
    "    return X[:index], X[index:]\n",
    "\n",
    "for sat_id in tqdm(sat_ids):\n",
    "    for cluster_index in range(24):\n",
    "        test_data  = test_clusters_list[sat_id][cluster_index]\n",
    "        train_data = clusters_list[sat_id][cluster_index]\n",
    "        transformer = Transformer()\n",
    "        X_train, X_test, y_train = transformer.fit_transform_test(train_data, test_data)\n",
    "        \n",
    "        rate = 0.5\n",
    "        if (len(test_data) < 6):\n",
    "            rate = 0.5\n",
    "            \n",
    "        X_test1, X_test2 = split(X_test, rate)\n",
    "        \n",
    "        _, X_train1 = split(X_train, 0.85)\n",
    "        _, y_train1 = split(y_train, 0.85)\n",
    "    \n",
    "        model1 = make_pipeline(PolynomialFeatures(degree=3), Ridge(alpha=0.0002))\n",
    "        model2 = Ridge(alpha=-0.001)\n",
    "    \n",
    "        for id_ in test_data['id']:\n",
    "            results[0].append(id_)\n",
    "        \n",
    "        subm = np.empty((len(test_data), 6))\n",
    "        X_train1_p = X_train1[:, [6]]\n",
    "        X_test1_p = X_test1[:, [6]]\n",
    "        \n",
    "        X_train2_p = np.vstack([X_train1[:, [6]], X_test1_p])\n",
    "        X_test2_p = X_test2[:, [6]]\n",
    "        \n",
    "        for feature_id in range(len(sim_features)):\n",
    "            y = y_train1[:, feature_id]\n",
    "            model1.fit(X_train1_p, y)\n",
    "            \n",
    "            y1 = model1.predict(X_test1_p)\n",
    "            model2.fit(X_train2_p, np.hstack([y, y1]))\n",
    "            \n",
    "            y2 = model2.predict(X_test2_p)\n",
    "        \n",
    "            subm[:, feature_id] = np.hstack([y1, y2])\n",
    "            \n",
    "        subm = transformer.inverse_transform(subm)\n",
    "        for feature_id in range(0, len(sim_features)):\n",
    "            results[feature_id + 1] += list(subm[:, feature_id])\n",
    "            \n",
    "\n",
    "                \n",
    "res_dict = {}\n",
    "for i, feature in enumerate(features):\n",
    "    res_dict[feature] = results[i + 1]\n",
    "    \n",
    "res_dict['id'] = results[0]\n",
    "answer = pd.DataFrame(res_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение предсказаний в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = answer.sort_values(by=['id']).set_index('id')\n",
    "tmp.to_csv(PATH_SAVE, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение последнего времени в кластере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_times, last_times = [], []\n",
    "sat_ids, cluster_ids = [], []\n",
    "\n",
    "for i in range(SAT_N):\n",
    "    for j in range(24):\n",
    "        times = list(clusters_list[i][j]['epoch'])\n",
    "        first_time = times[0]\n",
    "        last_time = times[-1]\n",
    "        \n",
    "        first_times.append(first_time)\n",
    "        last_times.append(last_time)\n",
    "        sat_ids.append(i)\n",
    "        cluster_ids.append(j)\n",
    "        \n",
    "result = {'sat_id' : sat_ids, 'cluster_id' : cluster_ids, 'last_time' : last_times}\n",
    "result = pd.DataFrame.from_dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('cluster_last_time.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тренировка модели для пункта B\n",
    "Сохранение коэффициентов скейлинга для каждой feature в каждом кластере в формате строк \n",
    "\n",
    "(номер_спутника номер_кластера номер_фичи медиана отклонение)\n",
    "\n",
    "scaled_x = (x - медиана) / отклонение\n",
    "\n",
    "\n",
    "Сохранение массива коэффициентов для Ridge - свободный член, коэффициенты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_split(X):\n",
    "    index = len(X) - 2\n",
    "    \n",
    "    while index >= 1 and ((X[index] - X[index - 1]) * (X[index + 1] - X[index]) > 0):\n",
    "        index -= 1\n",
    "        \n",
    "    index = max(0.85 * len(X), index)\n",
    "   # index = min(0.9 * len(X), index)\n",
    "    index = int(index)\n",
    "    \n",
    "    return X[:index], X[index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:33<00:00,  6.66it/s]\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(alpha=0.0003, tol=1e-8)\n",
    "\n",
    "coefs = [[[0] * 6 for _ in range(24)] for _ in range(SAT_N)]\n",
    "scalers = []\n",
    "\n",
    "for sat_id in tqdm(range(SAT_N)):\n",
    "    for cluster_id in range(24):\n",
    "        train_data = clusters_list[sat_id][cluster_id]\n",
    "        \n",
    "        transformer = Transformer()\n",
    "        X_train, y_train = transformer.fit_transform(train_data)\n",
    "        \n",
    "        sc = transformer.scalers\n",
    "        \n",
    "        means = [sc[i].mean_[0] for i in range(6)]\n",
    "        scales = [sc[i].scale_[0] for i in range(6)]\n",
    "        \n",
    "        _, X_train_p = super_split(X_train[:, [6]])\n",
    "        \n",
    "        y_train_p = [0] * 6\n",
    "        for feature_id in range(6):\n",
    "            _, y_train_p[feature_id] = super_split(y_train[:, feature_id])\n",
    "        \n",
    "                                        \n",
    "        for feature_id in range(6):\n",
    "            y = y_train_p[feature_id]\n",
    "            model.fit(X_train[-len(y):, [6]], y)\n",
    "        \n",
    "            coef = np.hstack([model.predict(np.array([[0]])), model.coef_])\n",
    "            coefs[sat_id][cluster_id][feature_id] = coef\n",
    "            scalers.append(' '.join(str(e) for e in [sat_id, cluster_id, feature_id, means[feature_id], scales[feature_id]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение коэффициентов и скейлинга в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file_scalers():\n",
    "    with open('scalers.txt', 'w') as f:\n",
    "        for line in scalers:\n",
    "            f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file_coefs():\n",
    "    with open('coefs.txt', 'w') as f:\n",
    "        for sat_id in range(SAT_N):\n",
    "            for cluster_id in range(24):\n",
    "                for feature_id in range(6):\n",
    "                    tmp_coefs = coefs[sat_id][cluster_id][feature_id]\n",
    "                    #print(tmp_coefs)\n",
    "                    #print(tmp_coefs[-1])\n",
    "                    line = ' '.join([str(sat_id), str(cluster_id), str(feature_id)]) + ' ' + ' '.join(str(coef) for coef in tmp_coefs)\n",
    "                    \n",
    "                    f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_file_coefs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_file_scalers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
