{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данное решение было оценено в 79.0. В нем использовалась линейная модель для предсказания ошибки приближенной модели в кватернионных координатах для всех координат, кроме аномалии (с учетом того, что эксцентриситет находится в промежутке от 0 до 1). Ошибка по аномалии раскладывалась на зависимость амлитуды колебаний от аномалии по приближенной модели и нормированные осцилляции. В результате, использовалась линейная модель для предсказания поведения амплитуды колебаний (с признаком-временем) и \n",
    "линейная модель для предсказания осцилляций (с признаками - синусом и косинусом приближенной аномалии)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\Standard\\lib\\site-packages\\tqdm\\std.py:654: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from coosys import cartesian_to_kepler as ctk, cartesian_to_quaternion as ctq\n",
    "from coosys import kepler_to_cartesian as ktc, quaternion_to_cartesian as qtc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.preprocessing import PolynomialFeatures as PF\n",
    "from scipy.interpolate import UnivariateSpline as US\n",
    "from scipy import signal\n",
    "import spectrum\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 1.3885 * 10**9\n",
    "\n",
    "train_data = pd.read_csv(\"IDAO 2020/train.csv\", encoding=\"utf8\")\n",
    "train_data[\"epoch\"] = pd.to_datetime(train_data[\"epoch\"]).apply(pd.Timestamp.timestamp) - base\n",
    "\n",
    "test_data = pd.read_csv(\"IDAO 2020/Track 1/test.csv\", encoding=\"utf8\")\n",
    "test_data[\"epoch\"] = pd.to_datetime(test_data[\"epoch\"]).apply(pd.Timestamp.timestamp) - base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_km = 398603\n",
    "\n",
    "def transform_row(row, func):\n",
    "    return func(row.values)\n",
    "\n",
    "def transform_dataset(data, func=lambda data: ctk(data, gamma_km), \n",
    "                      columns_from=(\"x\", \"y\", \"z\", \"Vx\", \"Vy\", \"Vz\"), \n",
    "                      columns_to=(\"a\", \"e\", \"inclination\", \"longitude\", \"argument\", \"anomaly\")):\n",
    "    new_data = data.loc[:, list(columns_from)].progress_apply(transform_row, axis=1, result_type=\"expand\", args=(func, ))\n",
    "    new_data.columns = columns_to\n",
    "    return data.drop(list(columns_from), axis=1).join(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072db7f447e341d58d970a5ad0da1f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=649912.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ae2d6d67c04fc88cef9b81f2553809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=649912.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_quaternion = transform_dataset(train_data, func=lambda data: ctq(data, gamma_km),\n",
    "                                     columns_from=(\"x\", \"y\", \"z\", \"Vx\", \"Vy\", \"Vz\"),\n",
    "                                     columns_to=((\"a\", \"e\", \"anomaly\", \"q1\", \"q2\", \"q3\", \"q4\")))\n",
    "train_quaternion = transform_dataset(train_quaternion, func=lambda data: ctq(data, gamma_km), \n",
    "                                     columns_from=(\"x_sim\", \"y_sim\", \"z_sim\", \"Vx_sim\", \"Vy_sim\", \"Vz_sim\"),\n",
    "                                     columns_to=(\"a_sim\", \"e_sim\", \"anomaly_sim\", \"q1_sim\", \"q2_sim\", \"q3_sim\", \"q4_sim\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_regression(phases):\n",
    "    periods = 0\n",
    "    new_phases = phases.copy()\n",
    "    for i in range(1, phases.size):\n",
    "        if phases[i] < phases[i - 1]:\n",
    "            periods += 1\n",
    "        new_phases[i] += 2 * np.pi * periods\n",
    "    return new_phases\n",
    "\n",
    "def phase_degression(phases):\n",
    "    new_phases = np.zeros_like(phases)\n",
    "    for i in range(phases.size):\n",
    "        new_phases[i] = phases[i] - 2 * np.pi * np.trunc(phases[i] / 2 / np.pi) \n",
    "    return new_phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sats_to_predict = set(test_data[\"sat_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7587ef08474239a5d6823ff18abbbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=284071.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_quaternion = transform_dataset(test_data, func=lambda data: ctq(data, gamma_km), \n",
    "                                    columns_from=(\"x_sim\", \"y_sim\", \"z_sim\", \"Vx_sim\", \"Vy_sim\", \"Vz_sim\"),\n",
    "                                    columns_to=(\"a_sim\", \"e_sim\", \"anomaly_sim\", \"q1_sim\", \"q2_sim\", \"q3_sim\", \"q4_sim\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(train_quaternion, test_quaternion, sat_id):\n",
    "    train_sat = train_quaternion[train_quaternion.sat_id == sat_id]\n",
    "    test_sat = test_quaternion[test_quaternion.sat_id == sat_id]\n",
    "    result = pd.DataFrame(columns=[\"id\", \"a\", \"e\", \"anomaly\", \"q1\", \"q2\", \"q3\", \"q4\"])\n",
    "    result[\"id\"] = test_sat[\"id\"]\n",
    "    train_t = train_sat[\"epoch\"].to_numpy().reshape(-1, 1)\n",
    "    train_features = PF(1, include_bias=False).fit_transform(train_t)\n",
    "    test_t = test_sat[\"epoch\"].to_numpy().reshape(-1, 1)\n",
    "    test_features = PF(1, include_bias=False).fit_transform(test_t)\n",
    "    \n",
    "    for coordinate in [\"a\", \"q1\", \"q2\", \"q3\", \"q4\"]:\n",
    "        train_diff = train_sat[coordinate] - train_sat[coordinate + \"_sim\"]\n",
    "        model = LR().fit(train_features, train_diff)\n",
    "        result[coordinate] = test_sat[coordinate + \"_sim\"] + model.predict(test_features)\n",
    "        \n",
    "    train_diff = train_sat[\"e\"] - train_sat[\"e_sim\"]\n",
    "    model = LR().fit(train_features, train_diff)\n",
    "    result[\"e\"] = test_sat[\"e_sim\"] + model.predict(test_features)\n",
    "    if np.any(result[\"e\"] < 0.) or np.any(result[\"e\"] >= 1.):\n",
    "        result[\"e\"] = test_sat[\"e_sim\"]\n",
    "        \n",
    "    fixed_anomaly_train = phase_regression(train_sat[\"anomaly\"].to_numpy())\n",
    "    fixed_anomaly_sim = phase_regression(np.concatenate([train_sat[\"anomaly_sim\"].to_numpy(),\n",
    "                                                         test_sat[\"anomaly_sim\"].to_numpy()]))\n",
    "    fixed_anomaly_train_sim = fixed_anomaly_sim[:train_sat[\"anomaly_sim\"].to_numpy().size]\n",
    "    fixed_anomaly_test_sim = fixed_anomaly_sim[train_sat[\"anomaly_sim\"].to_numpy().size:]\n",
    "    train_diff = fixed_anomaly_train - fixed_anomaly_train_sim\n",
    "    train_maxs = signal.argrelmax(train_diff)[0]\n",
    "    train_mins = signal.argrelmin(train_diff)[0]\n",
    "    maxs_spline = US(fixed_anomaly_train_sim[train_maxs], train_diff[train_maxs], s=0, k=1)\n",
    "    mins_spline = US(fixed_anomaly_train_sim[train_mins], train_diff[train_mins], s=0, k=1)\n",
    "    maxs_spline_all = maxs_spline(fixed_anomaly_train_sim)\n",
    "    mins_spline_all = mins_spline(fixed_anomaly_train_sim)\n",
    "    train_amplitude = maxs_spline_all - mins_spline_all\n",
    "    train_middle = (maxs_spline_all + mins_spline_all) / 2\n",
    "    train_rectified_oscillate = np.clip((train_diff - train_middle) / train_amplitude, -0.5, 0.5)\n",
    "    oscillate_features_train = np.concatenate([\n",
    "        np.cos(fixed_anomaly_train_sim).reshape(-1, 1),\n",
    "        np.sin(fixed_anomaly_train_sim).reshape(-1, 1),\n",
    "    ], axis=1)\n",
    "    maxs_model = LR().fit(train_features[train_maxs], train_diff[train_maxs])\n",
    "    mins_model = LR().fit(train_features[train_mins], train_diff[train_mins])\n",
    "    oscillate_model = LR(fit_intercept=False).fit(oscillate_features_train, train_rectified_oscillate)\n",
    "    oscillate_features_test = np.concatenate([\n",
    "        np.cos(fixed_anomaly_test_sim).reshape(-1, 1),\n",
    "        np.sin(fixed_anomaly_test_sim).reshape(-1, 1),\n",
    "    ], axis=1)\n",
    "    test_maxs = maxs_model.predict(test_features)\n",
    "    test_mins = mins_model.predict(test_features)\n",
    "    test_middle = (test_maxs + test_mins) / 2\n",
    "    test_amplitude = test_maxs - test_mins\n",
    "    test_oscillate = oscillate_model.predict(oscillate_features_test)\n",
    "    result[\"anomaly\"] = phase_degression(fixed_anomaly_test_sim + test_middle + test_amplitude * test_oscillate)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2d1963df5b49e7b1a49f95c0876d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for sat_id in tqdm(sats_to_predict):\n",
    "    results.append(predict_one(train_quaternion, test_quaternion, sat_id))\n",
    "    \n",
    "result_quaternion = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a2004fcf844ab38e8847636e3634f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=284071.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_cartesian = transform_dataset(result_quaternion, func=lambda data: qtc(data, gamma_km), \n",
    "                                     columns_from=(\"a\", \"e\", \"anomaly\", \"q1\", \"q2\", \"q3\", \"q4\"),\n",
    "                                     columns_to=(\"x\", \"y\", \"z\", \"Vx\", \"Vy\", \"Vz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cartesian = result_cartesian.sort_values(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cartesian.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
