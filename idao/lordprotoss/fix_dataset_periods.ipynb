{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = \"../competition_results/data/train.csv\" \n",
    "PATH_TEST = \"../competition_results/data/test.csv\"\n",
    "PATH_SAVE_TRAIN = \"../competition_results/data/train_fixed_period.csv\"\n",
    "PATH_SAVE_TEST = \"../competition_results/data/train_fixed_period.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\Standard\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from utils.coosys import cartesian_to_kepler as ctk, cartesian_to_quaternion as ctq\n",
    "from utils.coosys import kepler_to_cartesian as ktc, quaternion_to_cartesian as qtc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.preprocessing import PolynomialFeatures as PF\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from scipy.interpolate import UnivariateSpline as US\n",
    "from sklearn.pipeline import Pipeline as PL\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "from scipy import signal\n",
    "import spectrum\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(PATH_TRAIN, encoding=\"utf8\")\n",
    "train_data[\"timestamp\"] = pd.to_datetime(train_data[\"epoch\"]).apply(pd.Timestamp.timestamp)\n",
    "train_data = train_data.sort_values(by=\"timestamp\")\n",
    "\n",
    "test_data = pd.read_csv(PATH_TEST, encoding=\"utf8\")\n",
    "test_data[\"timestamp\"] = pd.to_datetime(test_data[\"epoch\"]).apply(pd.Timestamp.timestamp)\n",
    "test_data = test_data.sort_values(by=\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import argrelmax, argrelmin\n",
    "\n",
    "def evaluate_T(t, x):\n",
    "    return np.mean([np.mean(np.diff(t[argrelmin(x)])), np.mean(np.diff(t[argrelmax(x)]))])\n",
    "\n",
    "def evaluate_T_all(t, x):\n",
    "    return np.mean([evaluate_T(t, x[:, i]) for i in range(x.shape[1])])\n",
    "\n",
    "def prolong_sim(epoch, sim, T_sim, T_true, eps=0.1):\n",
    "    prolong_coef = T_sim / T_true + eps\n",
    "    \n",
    "    if prolong_coef < 1.:\n",
    "        return US(epoch, sim, k=1, s=0.)\n",
    "    \n",
    "    else:\n",
    "        future_periods = int((epoch[-1] - epoch[0]) / T_sim * (prolong_coef - 1.)) + 1\n",
    "        \n",
    "        full_epoch = np.zeros(epoch.size + future_periods * 24)\n",
    "        full_epoch[:epoch.size] = epoch[:]\n",
    "        \n",
    "        full_sim = np.zeros(sim.size + future_periods * 24)\n",
    "        full_sim[:sim.size] = sim[:]\n",
    "        \n",
    "        for i in range(24):\n",
    "            block_epoch = epoch[i::24]\n",
    "            block_sim = sim[i::24]\n",
    "            \n",
    "            block_future_epoch = (np.arange(future_periods) + 1) * T_sim + block_epoch[-1]\n",
    "            \n",
    "            base = LR().fit(block_epoch.reshape(-1, 1), block_sim)\n",
    "            block_predict = base.predict(block_future_epoch.reshape(-1, 1))\n",
    "            \n",
    "            full_epoch[i::24][-future_periods:] = block_future_epoch[:]\n",
    "            full_sim[i::24][-future_periods:] = block_predict[:]\n",
    "            \n",
    "        return US(full_epoch, full_sim, k=1, s=0.)\n",
    "    \n",
    "    \n",
    "def prolong_sim_all(epoch, sim, T_sim, T_true, eps=0.1):\n",
    "    return [prolong_sim(epoch, sim[:, i], T_sim, T_true, eps=0.1) for i in range(sim.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_sat(train, test, sat_id):\n",
    "    train_sat = train[train.sat_id == sat_id]\n",
    "    test_sat = test[test.sat_id == sat_id]\n",
    "    \n",
    "    train_sim = train_sat[[\"x_sim\", \"y_sim\", \"z_sim\", \"Vx_sim\", \"Vy_sim\", \"Vz_sim\"]].to_numpy()\n",
    "    test_sim = test_sat[[\"x_sim\", \"y_sim\", \"z_sim\", \"Vx_sim\", \"Vy_sim\", \"Vz_sim\"]].to_numpy()\n",
    "    train_epoch = train_sat[\"timestamp\"].to_numpy()\n",
    "    test_epoch = test_sat[\"timestamp\"].to_numpy()\n",
    "    \n",
    "    begin = np.min(train_epoch)\n",
    "    \n",
    "    train_epoch -= begin\n",
    "    test_epoch -= begin\n",
    "    \n",
    "    all_sim = np.concatenate([train_sim, test_sim], axis=0)\n",
    "    all_epoch = np.concatenate([train_epoch, test_epoch], axis=0)\n",
    "    \n",
    "    train_true = train_sat[[\"x\", \"y\", \"z\", \"Vx\", \"Vy\", \"Vz\"]].to_numpy()\n",
    "    \n",
    "    T_sim = evaluate_T_all(all_epoch, all_sim)\n",
    "    T_true = evaluate_T_all(train_epoch, train_true)\n",
    "    \n",
    "    koef = T_true / T_sim\n",
    "    \n",
    "    train_splines = prolong_sim_all(all_epoch, all_sim, T_sim, T_true)\n",
    "    \n",
    "    fixed_sim = np.zeros_like(all_sim)\n",
    "    for i in range(fixed_sim.shape[0]):\n",
    "        for j in range(fixed_sim.shape[1]):\n",
    "            fixed_sim[i, j] = train_splines[j](all_epoch[i] / koef)\n",
    "            \n",
    "    \n",
    "    new_train = pd.DataFrame(columns=[\"id\", \"epoch\", \"sat_id\", \"x\", \"y\", \"z\", \"Vx\", \"Vy\", \"Vz\", \n",
    "                                      \"x_sim\", \"y_sim\", \"z_sim\", \"Vx_sim\", \"Vy_sim\", \"Vz_sim\"])\n",
    "    new_train[\"id\"] = train_sat[\"id\"]\n",
    "    new_train[\"sat_id\"] = sat_id     \n",
    "    new_train[[\"x\", \"y\", \"z\", \"Vx\", \"Vy\", \"Vz\"]] = train_sat[[\"x\", \"y\", \"z\", \"Vx\", \"Vy\", \"Vz\"]]\n",
    "    new_train[\"epoch\"] = train_sat[\"epoch\"]\n",
    "    new_train[[\"x_sim\", \"y_sim\", \"z_sim\", \"Vx_sim\", \"Vy_sim\", \"Vz_sim\"]] = fixed_sim[:train_true.shape[0]]\n",
    "    \n",
    "    new_test = pd.DataFrame(columns=[\"id\", \"epoch\", \"sat_id\",\n",
    "                                     \"x_sim\", \"y_sim\", \"z_sim\", \"Vx_sim\", \"Vy_sim\", \"Vz_sim\"])\n",
    "    new_test[\"id\"] = test_sat[\"id\"]\n",
    "    new_test[\"sat_id\"] = sat_id\n",
    "    new_test[\"epoch\"] = test_sat[\"epoch\"]\n",
    "    new_test[[\"x_sim\", \"y_sim\", \"z_sim\", \"Vx_sim\", \"Vy_sim\", \"Vz_sim\"]] = fixed_sim[train_true.shape[0]:]\n",
    "\n",
    "    return new_train, new_test\n",
    "\n",
    "\n",
    "def fix_sat_train(train, sat_id):\n",
    "    train_sat = train[train.sat_id == sat_id]\n",
    "    \n",
    "    train_sim = train_sat[[\"x_sim\", \"y_sim\", \"z_sim\", \"Vx_sim\", \"Vy_sim\", \"Vz_sim\"]].to_numpy()\n",
    "    train_epoch = train_sat[\"timestamp\"].to_numpy()\n",
    "    \n",
    "    begin = np.min(train_epoch)\n",
    "    \n",
    "    train_epoch -= begin\n",
    "    \n",
    "    train_true = train_sat[[\"x\", \"y\", \"z\", \"Vx\", \"Vy\", \"Vz\"]].to_numpy()\n",
    "    \n",
    "    T_sim = evaluate_T_all(train_epoch, train_sim)\n",
    "    T_true = evaluate_T_all(train_epoch, train_true)\n",
    "    \n",
    "    koef = T_true / T_sim\n",
    "    \n",
    "    train_splines = prolong_sim_all(train_epoch, train_sim, T_sim, T_true)\n",
    "    \n",
    "    fixed_sim = np.zeros_like(train_sim)\n",
    "    for i in range(fixed_sim.shape[0]):\n",
    "        for j in range(fixed_sim.shape[1]):\n",
    "            fixed_sim[i, j] = train_splines[j](train_epoch[i] / koef)\n",
    "            \n",
    "    new_train = pd.DataFrame(columns=[\"sat_id\", \"epoch\", \"id\", \"x\", \"y\", \"z\", \"Vx\", \"Vy\", \"Vz\", \n",
    "                                      \"x_sim\", \"y_sim\", \"z_sim\", \"Vx_sim\", \"Vy_sim\", \"Vz_sim\"])\n",
    "    new_train[\"id\"] = train_sat[\"id\"]\n",
    "    new_train[\"sat_id\"] = sat_id     \n",
    "    new_train[[\"x\", \"y\", \"z\", \"Vx\", \"Vy\", \"Vz\"]] = train_sat[[\"x\", \"y\", \"z\", \"Vx\", \"Vy\", \"Vz\"]]\n",
    "    new_train[\"epoch\"] = train_sat[\"epoch\"]\n",
    "    new_train[[\"x_sim\", \"y_sim\", \"z_sim\", \"Vx_sim\", \"Vy_sim\", \"Vz_sim\"]] = fixed_sim[:train_true.shape[0]]\n",
    "\n",
    "    return new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sats_to_predict = set(test_data[\"sat_id\"].unique())\n",
    "sats_others = set(train_data[\"sat_id\"]) - sats_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddd264489a24aff815be7e6abe5c1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6707e954fb475b859bb41bf5e66be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_train = []\n",
    "new_test = []\n",
    "\n",
    "\n",
    "for sat_id in tqdm(sats_to_predict):\n",
    "    train_sat, test_sat = fix_sat(train_data, test_data, sat_id)\n",
    "    new_train.append(train_sat)\n",
    "    new_test.append(test_sat)\n",
    "    \n",
    "for sat_id in tqdm(sats_others):\n",
    "    train_sat = fix_sat_train(train_data, sat_id)\n",
    "    new_train.append(train_sat)\n",
    "    \n",
    "new_train = pd.concat(new_train)\n",
    "new_test = pd.concat(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.to_csv(PATH_SAVE_TRAIN, index=False)\n",
    "new_test.to_csv(PATH_SAVE_TEST, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
